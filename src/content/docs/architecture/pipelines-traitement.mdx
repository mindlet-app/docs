---
title: Pipelines de traitement
description: D√©tails des pipelines de traitement multimodal (PDF, Image, Audio, YouTube, Website)
sidebar:
  order: 5
---

import { Aside, Badge, Card, CardGrid, Steps, TabItem, Tabs } from '@astrojs/starlight/components';

# üîÑ Pipelines de traitement

<Badge text="Multimodal" variant="success" />
<Badge text="Mistral AI" variant="note" />

Mindlet AI dispose de **6 pipelines sp√©cialis√©s** pour traiter diff√©rents types de contenus. Chaque pipeline est optimis√© pour extraire le maximum d'information de sa source.

## Vue d'ensemble des pipelines

```mermaid
flowchart TB
    subgraph "Input Router"
        IR[input_router]
    end
    
    subgraph "Pipelines Sp√©cialis√©s"
        TEXT[Pipeline Texte]
        PDF[Pipeline PDF]
        IMG[Pipeline Image]
        AUDIO[Pipeline Audio]
        YT[Pipeline YouTube]
        WEB[Pipeline Website]
    end
    
    subgraph "Traitement Commun"
        DETECT[detect_complex_content]
        SPLIT[splitter_selection]
        CHUNK[splitter_application]
        ENRICH[chunk_enrichment]
        EMBED[embedding_generation]
    end
    
    IR --> TEXT
    IR --> PDF
    IR --> IMG
    IR --> AUDIO
    IR --> YT
    IR --> WEB
    
    TEXT --> DETECT
    PDF --> DETECT
    IMG --> DETECT
    AUDIO --> DETECT
    YT --> DETECT
    WEB --> DETECT
    
    DETECT --> SPLIT --> CHUNK --> ENRICH --> EMBED
```

---

## Pipeline Texte

Le pipeline le plus simple, pour le traitement de texte brut.

```mermaid
graph LR
    A[text_input_check] --> B[detect_complex_content]
    B --> C[splitter_selection]
    C --> D[splitter_application]
    D --> E{Complex?}
    E -->|Oui| F[chunk_enrichment]
    E -->|Non| G[embedding_generation]
    F --> G
    G --> H[END]
    
    style A fill:#e1f5fe
    style G fill:#c8e6c9
    style H fill:#bfb6fc
```

### Nodes du Pipeline Texte

| Node | Responsabilit√© |
|------|----------------|
| `text_input_check` | Valide le texte d'entr√©e |
| `detect_complex_content` | D√©tecte tables, code, formules |
| `splitter_selection` | Choisit le splitter appropri√© |
| `splitter_application` | Applique le chunking |
| `chunk_enrichment` | Enrichit les chunks complexes via LLM |
| `embedding_generation` | G√©n√®re les embeddings Mistral |

### D√©tection de contenu complexe

Le module `ContentComplexityDetector` analyse le texte pour identifier :

- **Tables** : Structures tabulaires (Markdown, HTML)
- **Code** : Blocs de code avec indentation ou syntaxe
- **Formules** : √âquations math√©matiques (LaTeX, MathML)
- **Listes structur√©es** : Listes √† plusieurs niveaux

---

## Pipeline PDF

Pipeline sophistiqu√© avec analyse de pages et strat√©gie de traitement adaptative.

```mermaid
graph TB
    A[document_input_check] --> B[pdf_loader]
    B --> C[pdf_cleaner]
    C --> D[pdf_page_analyzer]
    D --> E[pdf_processing_strategy]
    
    E -->|split_pages| F[pdf_split_by_pages]
    E -->|split_size| G[pdf_split_by_size]
    E -->|parse_only| H[pdf_text_parser]
    E -->|ocr_only| I[pdf_ocr_processor]
    E -->|hybrid| J[pdf_hybrid_processor]
    
    F --> H
    F --> I
    F --> J
    G --> H
    G --> I
    G --> J
    
    H --> K[pdf_content_merger]
    I --> K
    J --> K
    
    K --> L[detect_complex_content]
    
    style A fill:#e1f5fe
    style E fill:#fff9c4
    style K fill:#c8e6c9
```

### Strat√©gies de traitement PDF

```python
class ProcessingStrategy(str, Enum):
    """Strat√©gies de traitement PDF"""
    PARSE_ONLY = "parse_only"           # Extraction textuelle uniquement
    OCR_ONLY = "ocr_only"               # OCR uniquement (scans)
    HYBRID = "hybrid"                   # Parsing + OCR selon les pages
    SPLIT_THEN_PARSE = "split_then_parse"
    SPLIT_THEN_OCR = "split_then_ocr"

class SplitStrategy(str, Enum):
    """Strat√©gies de d√©coupage"""
    BY_PAGES = "by_pages"   # D√©coupage par nombre de pages
    BY_SIZE = "by_size"     # D√©coupage par taille
```

### Nodes du Pipeline PDF

<Tabs>
  <TabItem label="Chargement">
    | Node | Responsabilit√© |
    |------|----------------|
    | `pdf_loader` | Chargement depuis S3 |
    | `pdf_cleaner` | Nettoyage et normalisation |
    | `pdf_page_analyzer` | Analyse de chaque page |
  </TabItem>
  
  <TabItem label="Traitement">
    | Node | Responsabilit√© |
    |------|----------------|
    | `pdf_processing_strategy` | Choix de la strat√©gie |
    | `pdf_split_by_pages` | D√©coupage par pages |
    | `pdf_split_by_size` | D√©coupage par taille |
  </TabItem>
  
  <TabItem label="Extraction">
    | Node | Responsabilit√© |
    |------|----------------|
    | `pdf_text_parser` | Parsing texte natif |
    | `pdf_ocr_processor` | OCR avec Mistral |
    | `pdf_hybrid_processor` | Combinaison parsing + OCR |
    | `pdf_content_merger` | Fusion du contenu extrait |
  </TabItem>
</Tabs>

### Limites PDF

| Param√®tre | Valeur |
|-----------|--------|
| Taille max | 50 MB |
| Pages max | 1000 |
| Mod√®le OCR | mistral-ocr-latest |

---

## Pipeline Image

Utilise **Mistral Vision** pour g√©n√©rer une description textuelle de l'image.

```mermaid
graph LR
    A[image_input_check] --> B[image_loader]
    B -->|error| E[image_error_handler]
    B -->|continue| C[image_preprocessor]
    C -->|error| E
    C -->|continue| D[image_vision_analyzer]
    D -->|error| E
    D -->|continue| F[detect_complex_content]
    
    style A fill:#e1f5fe
    style D fill:#fff9c4
    style E fill:#ffcdd2
```

### Nodes du Pipeline Image

| Node | Responsabilit√© |
|------|----------------|
| `image_loader` | Chargement depuis S3 |
| `image_preprocessor` | Redimensionnement et optimisation |
| `image_vision_analyzer` | Analyse avec Mistral Vision |
| `image_error_handler` | Gestion des erreurs |

### Caract√©ristiques Image

| Param√®tre | Valeur |
|-----------|--------|
| Mod√®le Vision | mistral-small-latest |
| Taille max | 10 MB |
| R√©solution max | 1540x1540 |
| Formats support√©s | jpg, jpeg, png, webp, gif |

<Aside type="tip">
  Le pr√©processeur redimensionne automatiquement les images trop grandes pour respecter les limites de l'API Mistral Vision.
</Aside>

---

## Pipeline Audio

Transcription audio via **Voxtral** avec d√©coupage automatique pour les fichiers longs.

```mermaid
graph LR
    A[audio_input_check] --> B[audio_loader]
    B -->|error| E[audio_error_handler]
    B -->|continue| C[audio_splitter]
    C -->|error| E
    C -->|continue| D[audio_transcriber]
    D -->|error| E
    D -->|continue| F[detect_complex_content]
    
    style A fill:#e1f5fe
    style D fill:#fff9c4
    style E fill:#ffcdd2
```

### Nodes du Pipeline Audio

| Node | Responsabilit√© |
|------|----------------|
| `audio_loader` | Chargement depuis S3 |
| `audio_splitter` | D√©coupage en segments ‚â§ 15 min |
| `audio_transcriber` | Transcription avec Voxtral |
| `audio_error_handler` | Gestion des erreurs |

### Caract√©ristiques Audio

| Param√®tre | Valeur |
|-----------|--------|
| Mod√®le | voxtral-mini-latest |
| Dur√©e max par segment | 15 minutes |
| Formats support√©s | wav, mp3, m4a, flac, ogg |
| D√©coupage automatique | Si > 15 min |

<Aside type="note">
  Les fichiers audio de plus de 15 minutes sont automatiquement d√©coup√©s en segments pour respecter les limites de l'API Voxtral.
</Aside>

---

## Pipeline YouTube

R√©cup√®re la transcription via l'API YouTube, avec **fallback** sur le t√©l√©chargement audio si indisponible.

```mermaid
graph TB
    A[youtube_input_check] --> B{Transcription disponible?}
    B -->|Oui| C[youtube_transcript]
    B -->|Non| D[youtube_audio_download]
    C -->|success| E[detect_complex_content]
    C -->|fallback| D
    D --> F[audio_splitter]
    F --> G[audio_transcriber]
    G --> E
    
    A -->|error| H[youtube_error_handler]
    C -->|error| H
    D -->|error| H
    
    style A fill:#e1f5fe
    style C fill:#c8e6c9
    style D fill:#fff9c4
    style H fill:#ffcdd2
```

### Strat√©gie YouTube

<Steps>
1. **Tentative API**
   - R√©cup√©ration de la transcription via YouTubeTranscriptApi
   - Utilisation de proxy Webshare (IPs r√©sidentielles)

2. **Fallback Audio** (si transcription indisponible)
   - T√©l√©chargement de l'audio de la vid√©o
   - Routage vers le pipeline audio standard
</Steps>

### Nodes du Pipeline YouTube

| Node | Responsabilit√© |
|------|----------------|
| `youtube_input_check` | Validation de l'URL YouTube |
| `youtube_transcript` | R√©cup√©ration via API |
| `youtube_audio_download` | T√©l√©chargement audio (fallback) |
| `youtube_error_handler` | Gestion des erreurs |

<Aside type="caution">
  Certaines vid√©os YouTube n'ont pas de transcription disponible. Dans ce cas, le syst√®me t√©l√©charge automatiquement l'audio et le transcrit avec Voxtral.
</Aside>

---

## Pipeline Website

Crawl de sites web avec conversion en Markdown via **httpx** + **BeautifulSoup**.

```mermaid
graph LR
    A[website_input_check] --> B[website_crawler]
    B -->|error| E[website_error_handler]
    B -->|continue| C[website_content_cleaner]
    C -->|error| E
    C -->|continue| D[detect_complex_content]
    
    style A fill:#e1f5fe
    style C fill:#c8e6c9
    style E fill:#ffcdd2
```

### Nodes du Pipeline Website

| Node | Responsabilit√© |
|------|----------------|
| `website_input_check` | Validation de l'URL |
| `website_crawler` | Crawl avec httpx |
| `website_content_cleaner` | Nettoyage HTML ‚Üí Markdown |
| `website_error_handler` | Gestion des erreurs |

### Caract√©ristiques Website

| Caract√©ristique | D√©tail |
|-----------------|--------|
| **Compatible serverless** | Pas de navigateur requis |
| **Proxy Webshare** | IPs r√©sidentielles pour √©viter les blocages |
| **Conversion Markdown** | html2text pour un texte structur√© |
| **User-Agent rotatif** | Plusieurs UA r√©alistes |

<Aside type="tip">
  Le pipeline website est optimis√© pour les environnements serverless et n'utilise pas de navigateur headless (Puppeteer, Playwright) pour des raisons de performance et de compatibilit√©.
</Aside>

---

## Traitement commun

Apr√®s l'extraction du contenu par chaque pipeline, le traitement commun s'applique :

### 1. D√©tection de complexit√©

```python
class ContentComplexityDetector:
    """D√©tecte le contenu complexe n√©cessitant un traitement sp√©cial"""
    
    def detect(self, text: str) -> ComplexityResult:
        return ComplexityResult(
            has_tables=self._detect_tables(text),
            has_code=self._detect_code(text),
            has_formulas=self._detect_formulas(text),
            has_lists=self._detect_structured_lists(text)
        )
```

### 2. S√©lection du splitter

Le syst√®me choisit automatiquement le meilleur splitter :

| Type de contenu | Splitter utilis√© |
|-----------------|------------------|
| Texte simple | RecursiveCharacterTextSplitter |
| Code | CodeTextSplitter |
| Markdown | MarkdownTextSplitter |
| Contenu mixte | Combinaison intelligente |

### 3. Chunking

```python
CHUNK_SIZE = 512              # Taille cible en tokens
CHUNK_OVERLAP_PERCENT = 0.15  # 15% de chevauchement
CHUNK_OVERLAP = 77            # ~77 tokens
```

### 4. Enrichissement (optionnel)

Pour les chunks contenant du contenu complexe, un enrichissement LLM est appliqu√© pour pr√©server le contexte s√©mantique.

### 5. G√©n√©ration d'embeddings

```python
EMBEDDING_MODEL = "mistral-embed"
EMBEDDING_DIMENSION = 1024
EMBEDDING_BATCH_SIZE = 50
```

---

## Gestion des erreurs

Chaque pipeline dispose d'un **error handler** d√©di√© qui :

- Capture les exceptions sp√©cifiques au type de contenu
- G√©n√®re des messages d'erreur explicites
- Permet la continuation du traitement des autres ressources en mode batch

```python
class PipelineError(Exception):
    """Erreur g√©n√©rique de pipeline"""
    def __init__(self, message: str, pipeline: str, details: dict = None):
        self.message = message
        self.pipeline = pipeline
        self.details = details or {}
```

---

*Pipelines de traitement multimodal pour une extraction de contenu optimale.*
