---
title: Service Intelligence Artificielle
description: Architecture et fonctionnement du service IA de Mindlet
sidebar:
  order: 4
---

import { Aside, Badge, Card, CardGrid, Steps, TabItem, Tabs } from '@astrojs/starlight/components';

# ğŸ¤– Service Intelligence Artificielle

<Badge text="LangChain" variant="success" />
<Badge text="LangGraph" variant="note" />
<Badge text="Qdrant" variant="caution" />

## Vue d'ensemble

Le service IA est le cÅ“ur de Mindlet, responsable de la **gÃ©nÃ©ration automatique de contenu pÃ©dagogique** Ã  partir de documents importÃ©s par les utilisateurs.

<Aside type="note">
  Notre technologie d'IA propriÃ©taire est capable d'analyser, comprendre et transformer n'importe quel contenu en outils d'apprentissage interactifs.
</Aside>

## Stack technique

| Composant | Technologie | RÃ´le |
|-----------|-------------|------|
| **Orchestration** | LangChain | ChaÃ®nes de traitement LLM |
| **Agents** | LangGraph | Graphes d'agents intelligents |
| **Embeddings** | OpenAI / Ollama | Vectorisation des contenus |
| **Base vectorielle** | Qdrant | Stockage et recherche sÃ©mantique |
| **LLM** | GPT-4 / Claude / Mistral | GÃ©nÃ©ration de texte |

## Architecture du service

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SERVICE IA                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Document   â”‚  â”‚   Content    â”‚  â”‚   Question   â”‚      â”‚
â”‚  â”‚   Ingestion  â”‚â”€â”€â”‚   Analysis   â”‚â”€â”€â”‚   Generation â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚         â”‚                â”‚                  â”‚               â”‚
â”‚         â–¼                â–¼                  â–¼               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Embedding  â”‚  â”‚   Semantic   â”‚  â”‚   Card       â”‚      â”‚
â”‚  â”‚   Service    â”‚  â”‚   Search     â”‚  â”‚   Builder    â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚         â”‚                â”‚                  â”‚               â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                          â–¼                                  â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚                   â”‚    Qdrant    â”‚                         â”‚
â”‚                   â”‚   Vector DB  â”‚                         â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Pipeline de traitement

<Steps>
1. **Ingestion du document**
   - Extraction du texte (PDF, DOCX, PPTX, audio, vidÃ©o)
   - Nettoyage et normalisation
   - DÃ©coupage en chunks

2. **Analyse du contenu**
   - Identification des concepts clÃ©s
   - Extraction des dÃ©finitions
   - DÃ©tection de la structure

3. **Vectorisation**
   - GÃ©nÃ©ration des embeddings
   - Stockage dans Qdrant
   - Indexation pour la recherche

4. **GÃ©nÃ©ration des questions**
   - CrÃ©ation de questions variÃ©es
   - Validation de la pertinence
   - Formatage selon le type de carte

5. **Construction des cartes**
   - Assemblage question/rÃ©ponse
   - Ajout des mÃ©tadonnÃ©es
   - Classification par difficultÃ©
</Steps>

## ChaÃ®nes LangChain

### Document Processing Chain

```python
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate

document_analysis_prompt = PromptTemplate(
    input_variables=["content"],
    template="""
    Analysez le contenu suivant et extrayez:
    1. Les concepts clÃ©s (5-10 maximum)
    2. Les dÃ©finitions importantes
    3. Les relations entre concepts
    4. Les points difficiles Ã  mÃ©moriser
    
    Contenu:
    {content}
    
    RÃ©pondez en JSON structurÃ©.
    """
)

analysis_chain = LLMChain(
    llm=llm,
    prompt=document_analysis_prompt,
    output_parser=JsonOutputParser()
)
```

### Question Generation Chain

```python
question_generation_prompt = PromptTemplate(
    input_variables=["concept", "context", "difficulty"],
    template="""
    GÃ©nÃ¨re une question pÃ©dagogique sur le concept suivant:
    
    Concept: {concept}
    Contexte: {context}
    DifficultÃ©: {difficulty}
    
    La question doit:
    - ÃŠtre claire et non ambiguÃ«
    - Tester la comprÃ©hension, pas la mÃ©morisation brute
    - Avoir une rÃ©ponse vÃ©rifiable
    
    Format de sortie:
    {{
        "question": "...",
        "answer": "...",
        "explanation": "...",
        "difficulty": 1-5
    }}
    """
)
```

## Agents LangGraph

### Agent de gÃ©nÃ©ration adaptative

<Tabs>
  <TabItem label="Architecture">
    ```python
    from langgraph.graph import StateGraph, END

    class GenerationState(TypedDict):
        document: str
        concepts: List[str]
        questions: List[Dict]
        cards: List[Card]
        quality_score: float

    def create_generation_graph():
        workflow = StateGraph(GenerationState)
        
        # NÅ“uds du graphe
        workflow.add_node("extract_concepts", extract_concepts)
        workflow.add_node("generate_questions", generate_questions)
        workflow.add_node("validate_quality", validate_quality)
        workflow.add_node("build_cards", build_cards)
        workflow.add_node("regenerate", regenerate_low_quality)
        
        # Transitions
        workflow.add_edge("extract_concepts", "generate_questions")
        workflow.add_conditional_edges(
            "generate_questions",
            check_quality,
            {
                "pass": "build_cards",
                "fail": "regenerate"
            }
        )
        workflow.add_edge("regenerate", "validate_quality")
        workflow.add_edge("build_cards", END)
        
        return workflow.compile()
    ```
  </TabItem>
  
  <TabItem label="Validation qualitÃ©">
    ```python
    def validate_quality(state: GenerationState) -> GenerationState:
        """Ã‰value la qualitÃ© des questions gÃ©nÃ©rÃ©es."""
        
        quality_prompt = """
        Ã‰valuez la qualitÃ© de cette question pÃ©dagogique:
        
        Question: {question}
        RÃ©ponse: {answer}
        
        CritÃ¨res (0-1 chacun):
        - ClartÃ©
        - Pertinence pÃ©dagogique
        - VÃ©rifiabilitÃ© de la rÃ©ponse
        - Niveau de difficultÃ© appropriÃ©
        
        Score global (moyenne des critÃ¨res):
        """
        
        scores = []
        for q in state["questions"]:
            score = evaluate_question(q, quality_prompt)
            scores.append(score)
        
        state["quality_score"] = sum(scores) / len(scores)
        return state

    def check_quality(state: GenerationState) -> str:
        """DÃ©cide si la qualitÃ© est suffisante."""
        if state["quality_score"] >= 0.7:
            return "pass"
        return "fail"
    ```
  </TabItem>
</Tabs>

## Embeddings et recherche sÃ©mantique

### Configuration Qdrant

```python
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams

client = QdrantClient(host="qdrant", port=6333)

# CrÃ©ation de la collection
client.create_collection(
    collection_name="mindlet_documents",
    vectors_config=VectorParams(
        size=1536,  # Dimension OpenAI
        distance=Distance.COSINE
    )
)
```

### Service d'embedding

```python
class EmbeddingService:
    def __init__(self, model: str = "text-embedding-3-small"):
        self.model = model
        self.client = OpenAI()
    
    async def embed_document(self, document: Document) -> List[float]:
        """GÃ©nÃ¨re l'embedding d'un document."""
        chunks = self.chunk_document(document.content)
        embeddings = []
        
        for chunk in chunks:
            response = await self.client.embeddings.create(
                model=self.model,
                input=chunk
            )
            embeddings.append({
                "vector": response.data[0].embedding,
                "metadata": {
                    "document_id": document.id,
                    "chunk_index": chunks.index(chunk),
                    "text": chunk
                }
            })
        
        return embeddings
    
    async def search_similar(
        self, 
        query: str, 
        limit: int = 5
    ) -> List[Dict]:
        """Recherche les contenus similaires."""
        query_embedding = await self.embed_text(query)
        
        results = self.qdrant.search(
            collection_name="mindlet_documents",
            query_vector=query_embedding,
            limit=limit
        )
        
        return [
            {
                "text": hit.payload["text"],
                "score": hit.score,
                "document_id": hit.payload["document_id"]
            }
            for hit in results
        ]
```

## Types de cartes gÃ©nÃ©rÃ©es

<CardGrid>
  <Card title="Flashcard" icon="document">
    Question/rÃ©ponse simple pour la mÃ©morisation
  </Card>
  <Card title="QCM" icon="list-format">
    Question Ã  choix multiples avec distracteurs
  </Card>
  <Card title="Vrai/Faux" icon="approve-check">
    Affirmation Ã  valider avec explication
  </Card>
  <Card title="Association" icon="puzzle">
    Relier des Ã©lÃ©ments correspondants
  </Card>
  <Card title="Texte Ã  trous" icon="pencil">
    ComplÃ©ter les mots manquants
  </Card>
  <Card title="Carte mentale" icon="star">
    Visualisation des relations entre concepts
  </Card>
</CardGrid>

### GÃ©nÃ©ration de QCM

```python
def generate_mcq(concept: str, context: str) -> Dict:
    """GÃ©nÃ¨re un QCM avec distracteurs pertinents."""
    
    prompt = f"""
    CrÃ©ez un QCM sur: {concept}
    Contexte: {context}
    
    GÃ©nÃ©rez:
    - 1 bonne rÃ©ponse
    - 3 distracteurs plausibles mais incorrects
    
    Les distracteurs doivent:
    - ÃŠtre vraisemblables
    - Cibler des erreurs de comprÃ©hension courantes
    - Ne pas Ãªtre trivialement faux
    """
    
    response = llm.generate(prompt)
    
    return {
        "type": "mcq",
        "question": response.question,
        "correct_answer": response.correct,
        "options": shuffle([
            response.correct,
            *response.distractors
        ]),
        "explanation": response.explanation
    }
```

## Performance et optimisation

### Caching

```python
from functools import lru_cache
import redis

redis_client = redis.Redis(host='redis', port=6379)

def cache_embedding(func):
    """Decorator pour cacher les embeddings."""
    async def wrapper(text: str) -> List[float]:
        cache_key = f"embedding:{hash(text)}"
        
        cached = redis_client.get(cache_key)
        if cached:
            return json.loads(cached)
        
        embedding = await func(text)
        redis_client.setex(cache_key, 3600, json.dumps(embedding))
        
        return embedding
    return wrapper
```

### Batch processing

```python
async def process_batch(documents: List[Document]) -> List[Card]:
    """Traite plusieurs documents en parallÃ¨le."""
    
    tasks = [
        asyncio.create_task(process_document(doc))
        for doc in documents
    ]
    
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    cards = []
    for result in results:
        if isinstance(result, Exception):
            logger.error(f"Error processing document: {result}")
        else:
            cards.extend(result)
    
    return cards
```

## MÃ©triques et monitoring

| MÃ©trique | Description | Cible |
|----------|-------------|-------|
| **Latence gÃ©nÃ©ration** | Temps pour gÃ©nÃ©rer des cartes | < 10s |
| **QualitÃ© questions** | Score moyen de validation | > 0.7 |
| **Taux de succÃ¨s** | Documents traitÃ©s sans erreur | > 95% |
| **Utilisation cache** | Hit rate du cache embeddings | > 60% |

---

*Intelligence artificielle au service de l'apprentissage personnalisÃ©.*
