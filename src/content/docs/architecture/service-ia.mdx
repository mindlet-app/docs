---
title: Service Intelligence Artificielle
description: Architecture et fonctionnement du service IA de Mindlet bas√© sur LangGraph
sidebar:
  order: 4
---

import { Aside, Badge, Card, CardGrid, Steps, TabItem, Tabs } from '@astrojs/starlight/components';

# ü§ñ Service Intelligence Artificielle

<Badge text="LangGraph" variant="success" />
<Badge text="Mistral AI" variant="note" />
<Badge text="Python" variant="caution" />

## Vue d'ensemble

Le service IA est le **c≈ìur du traitement intelligent** de Mindlet. Son r√¥le principal est de transformer n'importe quel type de contenu (texte, PDF, images, audio, vid√©os YouTube, sites web) en cartes d'apprentissage personnalis√©es et efficaces.

### Ce que fait le service IA

- üìù **Extraire** du contenu depuis diff√©rentes sources (texte, PDF, images, audio, vid√©os YouTube, sites web)
- üî¢ **G√©n√©rer des embeddings** vectoriels via Mistral AI
- üé¥ **Cr√©er des cartes d'apprentissage** intelligentes (flashcards, QCM, etc.)

<Aside type="tip" title="Pourquoi un service IA d√©di√© ?">
  Plut√¥t que d'int√©grer l'IA directement dans le backend principal, nous avons choisi de cr√©er un **microservice ind√©pendant**. Cette architecture permet :
  - Une **scalabilit√© horizontale** : le service IA peut √™tre r√©pliqu√© ind√©pendamment selon la charge
  - Une **isolation des d√©pendances** : les librairies ML lourdes ne polluent pas le backend principal
  - Une **√©volutivit√©** : on peut changer de mod√®le ou de provider sans impacter le reste du syst√®me
</Aside>

### Qu'est-ce que LangGraph ?

**LangGraph** est un framework Python d√©velopp√© par LangChain pour cr√©er des **workflows IA orchestr√©s sous forme de graphes**. Contrairement √† une simple cha√Æne lin√©aire de prompts, LangGraph permet :

- Des **branchements conditionnels** : le flux de traitement s'adapte dynamiquement au contenu
- Des **boucles de feedback** : un agent peut critiquer et am√©liorer it√©rativement son travail
- Une **gestion d'√©tat explicite** : chaque √©tape re√ßoit et modifie un √©tat typ√© (TypedDict)
- Une **visualisation native** : les graphes sont exportables en Mermaid pour la documentation

```python
# Exemple simplifi√© : un graphe LangGraph se construit comme un DAG
workflow = StateGraph(MyState)           # On d√©finit l'√©tat qui traverse le graphe
workflow.add_node("etape1", fonction_1)  # Chaque node est une fonction Python
workflow.add_node("etape2", fonction_2)
workflow.add_edge("etape1", "etape2")    # Les edges connectent les nodes
graph = workflow.compile()               # Le graphe compil√© est invocable
```

### Pourquoi Mistral AI ?

Nous avons choisi **Mistral AI** comme provider principal pour plusieurs raisons strat√©giques :

1. **Souverainet√© europ√©enne** : Mistral est une entreprise fran√ßaise, ce qui simplifie la conformit√© RGPD
2. **Rapport qualit√©/prix** : Performances comparables √† GPT-4 pour un co√ªt significativement inf√©rieur
3. **Suite compl√®te** : Un seul provider pour LLM, embeddings, OCR, vision et transcription audio
4. **API consistante** : Toutes les APIs suivent le m√™me pattern, simplifiant l'int√©gration

## Stack technique

| Composant | Technologie | R√¥le |
|-----------|-------------|------|
| **Orchestration** | LangGraph | Graphes d'agents intelligents |
| **LLM Principal** | Mistral AI (mistral-medium-latest) | G√©n√©ration de texte |
| **Embeddings** | mistral-embed (1024 dimensions) | Vectorisation des contenus |
| **Vision** | mistral-small-latest | Analyse d'images |
| **OCR** | mistral-ocr-latest | Reconnaissance de texte |
| **Transcription** | voxtral-mini-latest | Audio vers texte |
| **Stockage** | AWS S3 | Fichiers et m√©dias |
| **Framework** | LangChain | Cha√Ænes de traitement |

## Architecture globale

Le syst√®me est compos√© de **3 graphes LangGraph** principaux qui orchestrent le traitement :

```mermaid
flowchart TB
    subgraph "Mindlet AI Platform"
        INPUT["üì• Inputs<br/>(Text, PDF, Image, Audio, YouTube, Website)"]
        
        subgraph "Processing Layer"
            EG["üîÑ Embedding Graph<br/>(Single Resource)"]
            BEG["üì¶ Batch Embedding Graph<br/>(Multiple Resources)"]
            CGG["üé¥ Card Generator Graph<br/>(Agentic)"]
        end
        
        OUTPUT["üì§ Outputs"]
    end
    
    INPUT --> |"Single Resource"| EG
    INPUT --> |"Multiple Resources"| BEG
    EG --> |"Embedded Chunks"| CGG
    BEG --> |"Aggregated Chunks"| CGG
    
    EG --> OUTPUT
    BEG --> OUTPUT
    CGG --> OUTPUT
```

## Les 3 graphes principaux

Le syst√®me est organis√© autour de **3 graphes LangGraph** qui collaborent pour transformer du contenu brut en cartes d'apprentissage. Comprendre leurs responsabilit√©s est essentiel pour appr√©hender l'architecture :

<CardGrid>
  <Card title="1. Embedding Graph" icon="document">
    **Le transformateur de contenu.** Ce graphe prend une ressource unique (un PDF, une image, un audio...) et la convertit en "chunks" vectoris√©s. Il d√©tecte automatiquement le type d'input et route vers le pipeline de traitement appropri√©.
  </Card>
  <Card title="2. Batch Embedding Graph" icon="list-format">
    **L'orchestrateur de masse.** Quand un utilisateur importe plusieurs ressources √† la fois, ce graphe les traite en parall√®le via asyncio puis agr√®ge les r√©sultats. Il utilise le graphe d'embedding individuel en interne.
  </Card>
  <Card title="3. Card Generator Graph" icon="rocket">
    **Le cr√©ateur p√©dagogique.** C'est un graphe "agentic" sophistiqu√© compos√© de 5 agents (Planner, Generator, Critic, Refiner, Finalizer) qui collaborent pour produire des cartes d'apprentissage de haute qualit√© √† partir des chunks vectoris√©s.
  </Card>
</CardGrid>

### Flux de donn√©es entre les graphes

```mermaid
flowchart LR
    A["üìÑ Ressource brute"] --> B["üîÑ Embedding Graph"]
    B --> C["üìä Chunks vectoris√©s"]
    C --> D["üé¥ Card Generator"]
    D --> E["‚úÖ Cartes d'apprentissage"]
    
    F["üìö Plusieurs ressources"] --> G["üì¶ Batch Embedding Graph"]
    G --> B
    
    style A fill:#e3f2fd,stroke:#1976d2
    style B fill:#fff3e0,stroke:#f57c00
    style C fill:#f3e5f5,stroke:#7b1fa2
    style D fill:#e8f5e9,stroke:#388e3c
    style E fill:#c8e6c9,stroke:#2e7d32
    style F fill:#e3f2fd,stroke:#1976d2
    style G fill:#fff3e0,stroke:#f57c00
```

<Aside type="note" title="Qu'est-ce qu'un chunk ?">
  Un **chunk** est un segment de texte de taille contr√¥l√©e (512 tokens dans notre cas) accompagn√© de son **embedding** (vecteur de 1024 dimensions). Le chunking permet de traiter de longs documents tout en pr√©servant le contexte s√©mantique.
</Aside>

## Types d'input support√©s

Le syst√®me d√©tecte automatiquement le type de contenu et applique le traitement appropri√© :

```python
class InputType(str, Enum):
    """Types d'input pour le graph embedding.
    
    Chaque type d√©clenche un pipeline de traitement sp√©cifique
    optimis√© pour extraire le contenu de mani√®re optimale.
    """
    TEXT = "text"         # Texte brut ‚Üí chunking direct
    DOCUMENT = "document" # PDFs ‚Üí parsing texte ou OCR
    IMAGE = "image"       # Images ‚Üí description par vision IA
    AUDIO = "audio"       # Fichiers audio ‚Üí transcription
    YOUTUBE = "youtube"   # URLs YouTube ‚Üí r√©cup transcription ou fallback audio
    WEBSITE = "website"   # URLs web ‚Üí crawl et conversion markdown
    VIDEO = "video"       # Fichiers vid√©o ‚Üí extraction audio puis transcription
```

## Pipeline de traitement unifi√©

Quelle que soit la source, le contenu suit toujours ces √©tapes. Ce pipeline unifi√© garantit une **qualit√© constante** des embeddings produits :

<Steps>
1. **D√©tection du type d'input**
   - Analyse automatique de la ressource
   - Routage vers le pipeline appropri√©

2. **Extraction du contenu**
   - PDF : Parsing texte ou OCR selon la complexit√©
   - Image : Analyse vision avec Mistral
   - Audio : Transcription avec Voxtral
   - Vid√©o YouTube : API transcription ou fallback audio
   - Site web : Crawl et conversion Markdown

3. **D√©tection de contenu complexe**
   - Identification des tables, code, formules
   - S√©lection du splitter appropri√©

4. **Chunking intelligent**
   - D√©coupage en segments de 512 tokens
   - Chevauchement de 15% pour la coh√©rence

5. **Enrichissement (si n√©cessaire)**
   - Enrichissement LLM des chunks complexes
   - Pr√©servation de la structure s√©mantique

6. **G√©n√©ration des embeddings**
   - Vectorisation via mistral-embed
   - Dimension : 1024
   - Batch de 50 textes par appel
</Steps>

## Diagramme du Embedding Graph

```mermaid
graph TD;
    __start__([__start__]):::first
    input_router(input_router)
    audio_input_check(audio_input_check)
    youtube_input_check(youtube_input_check)
    image_input_check(image_input_check)
    text_input_check(text_input_check)
    website_input_check(website_input_check)
    document_input_check(document_input_check)
    detect_complex_content(detect_complex_content)
    splitter_selection(splitter_selection)
    splitter_application(splitter_application)
    chunk_enrichment(chunk_enrichment)
    embedding_generation(embedding_generation)
    __end__([__end__]):::last
    
    __start__ --> input_router;
    input_router -.-> audio_input_check;
    input_router -.-> document_input_check;
    input_router -.-> image_input_check;
    input_router -.-> text_input_check;
    input_router -.-> website_input_check;
    input_router -.-> youtube_input_check;
    
    text_input_check --> detect_complex_content;
    detect_complex_content --> splitter_selection;
    splitter_selection --> splitter_application;
    splitter_application -. enrich .-> chunk_enrichment;
    splitter_application -. skip .-> embedding_generation;
    chunk_enrichment --> embedding_generation;
    embedding_generation --> __end__;
    
    classDef default fill:#f2f0ff,line-height:1.2
    classDef first fill-opacity:0
    classDef last fill:#bfb6fc
```

## Configuration et constantes

<Tabs>
  <TabItem label="Chunking">
    ```python
    # === Chunking ===
    CHUNK_SIZE = 512              # Taille des chunks en tokens
    CHUNK_OVERLAP_PERCENT = 0.15  # 15% de chevauchement
    CHUNK_OVERLAP = 77            # ~77 tokens de chevauchement
    ```
  </TabItem>
  
  <TabItem label="Embeddings">
    ```python
    # === Embeddings Mistral ===
    EMBEDDING_MODEL = "mistral-embed"
    EMBEDDING_DIMENSION = 1024
    EMBEDDING_BATCH_SIZE = 50     # Textes par appel API
    ```
  </TabItem>
  
  <TabItem label="Limites">
    ```python
    # === Limites ===
    MAX_PDF_SIZE_MB = 50
    MAX_PDF_PAGES = 1000
    MAX_AUDIO_DURATION_SECONDS = 900  # 15 minutes
    ```
  </TabItem>
  
  <TabItem label="Mod√®les">
    ```python
    # === Mod√®les Mistral ===
    OCR_MODEL = "mistral-ocr-latest"
    TRANSCRIPTION_MODEL = "voxtral-mini-latest"
    VISION_MODEL = "mistral-small-latest"
    LLM_MODEL = "mistral-medium-latest"
    ```
  </TabItem>
</Tabs>

## Structure d'un chunk embedd√©

```python
{
    "id": "chunk_001",
    "text": "Contenu du chunk...",
    "embedding": [0.123, 0.456, ...],  # 1024 dimensions
    "metadata": {
        "source": "document.pdf",
        "page": 1,
        "chunk_index": 0,
        "has_complex_content": False
    }
}
```

## Extensions support√©es

| Type | Extensions |
|------|------------|
| **PDF** | `.pdf` |
| **Images** | `.jpg`, `.jpeg`, `.png`, `.webp`, `.gif` |
| **Audio** | `.wav`, `.mp3`, `.m4a`, `.flac`, `.ogg` |
| **Vid√©o** | `.mp4`, `.avi`, `.mov`, `.mkv`, `.webm` |

## M√©triques et performance

| M√©trique | Description | Cible |
|----------|-------------|-------|
| **Latence embedding** | Temps pour g√©n√©rer les embeddings | < 5s / chunk |
| **Qualit√© extraction** | Pr√©cision de l'extraction de contenu | > 95% |
| **Taux de succ√®s** | Ressources trait√©es sans erreur | > 98% |
| **Throughput batch** | Ressources trait√©es par minute | > 20 |

## Architecture d√©taill√©e

Pour plus de d√©tails sur chaque composant :

<CardGrid>
  <Card title="Pipelines de traitement" icon="setting">
    D√©tails des pipelines PDF, Image, Audio, YouTube et Website.
    
    [Voir les pipelines ‚Üí](/architecture/pipelines-traitement/)
  </Card>
  <Card title="Graphes LangGraph" icon="rocket">
    Architecture d√©taill√©e des graphes d'embedding et batch.
    
    [Voir les graphes ‚Üí](/architecture/graphes-langgraph/)
  </Card>
  <Card title="G√©n√©ration de cartes" icon="star">
    Architecture agentic du Card Generator Graph.
    
    [Voir la g√©n√©ration ‚Üí](/architecture/generation-cartes/)
  </Card>
</CardGrid>

---

*Intelligence artificielle multimodale au service de l'apprentissage personnalis√©.*
